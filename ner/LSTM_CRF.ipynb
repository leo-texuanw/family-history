{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- https://guillaumegenthial.github.io/introduction-tensorflow-estimator.html\n",
    "- [NER with keras and tf](https://towardsdatascience.com/named-entity-recognition-ner-meeting-industrys-requirement-by-applying-state-of-the-art-deep-698d2b3b4ede)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- split train/val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_input():\n",
    "    gen = input_layer(params[\"texts\"], params[\"tags\"], params)\n",
    "    for i in gen:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Early stopping\n",
    "# train_input = functools.partial(input_layer, '')\n",
    "\n",
    "# # 1. Define our input_fn\n",
    "# train_inpf = functools.partial(input_fn, 'words.train.txt', 'tags.train.txt',\n",
    "#                                params, shuffle_and_repeat=True)\n",
    "# eval_inpf = functools.partial(input_fn,'words.testa.txt', 'tags.testa.txt'\n",
    "#                               params)\n",
    "\n",
    "# # 2. Create a hook\n",
    "# Path(estimator.eval_dir()).mkdir(parents=True, exist_ok=True)\n",
    "# hook = tf.contrib.estimator.stop_if_no_increase_hook(\n",
    "#     estimator, 'f1', 500, min_steps=8000, run_every_secs=120)\n",
    "# train_spec = tf.estimator.TrainSpec(input_fn=input_fn, hooks=[hook])\n",
    "# eval_spec = tf.estimator.EvalSpec(input_fn=eval_inpf, throttle_secs=120)\n",
    "\n",
    "# # 3. Train with early stopping\n",
    "# tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config: {'_model_dir': 'results/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 120, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe6246fd2e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:09.777227 140632884213504 estimator.py:209] Using config: {'_model_dir': 'results/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 120, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe6246fd2e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished loadingfinished loadingfinished loadingfinished loadingfinished loadingfinished loadingfinished loadingfinished loadingfinished loadingfinished loading\n",
      "Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:09.779948 140632884213504 estimator_training.py:186] Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:09.781280 140632884213504 training.py:612] Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 120.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:09.782692 140632884213504 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 120.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:09.840014 140632884213504 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:12.055577 140632884213504 estimator.py:1147] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:12.058851 140632884213504 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:12.204302 140632884213504 monitored_session.py:240] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:12.404622 140632884213504 session_manager.py:500] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:12.448480 140632884213504 session_manager.py:502] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoints for 0 into results/model/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:13.887341 140632884213504 basic_session_run_hooks.py:606] Saving checkpoints for 0 into results/model/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 32.069607, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:16.402629 140632884213504 basic_session_run_hooks.py:262] loss = 32.069607, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 17.3972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:22.149894 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 17.3972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 5.046631, step = 101 (5.750 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:22.152168 140632884213504 basic_session_run_hooks.py:260] loss = 5.046631, step = 101 (5.750 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 19.7285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:27.218683 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 19.7285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 3.7069137, step = 201 (5.070 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:27.222668 140632884213504 basic_session_run_hooks.py:260] loss = 3.7069137, step = 201 (5.070 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 20.6263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:32.066840 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 20.6263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 4.9520836, step = 301 (4.849 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:32.071809 140632884213504 basic_session_run_hooks.py:260] loss = 4.9520836, step = 301 (4.849 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 20.4083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:36.966859 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 20.4083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.6843735, step = 401 (4.898 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:36.969481 140632884213504 basic_session_run_hooks.py:260] loss = 1.6843735, step = 401 (4.898 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 21.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:41.723782 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 21.0216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 2.1974556, step = 501 (4.757 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:41.726386 140632884213504 basic_session_run_hooks.py:260] loss = 2.1974556, step = 501 (4.757 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 20.8116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:46.528851 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 20.8116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 4.400283, step = 601 (4.806 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:46.532131 140632884213504 basic_session_run_hooks.py:260] loss = 4.400283, step = 601 (4.806 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 20.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:51.365590 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 20.675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 2.469675, step = 701 (4.839 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:51.371381 140632884213504 basic_session_run_hooks.py:260] loss = 2.469675, step = 701 (4.839 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 20.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:56.361247 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 20.0176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.9749228, step = 801 (4.995 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:10:56.366776 140632884213504 basic_session_run_hooks.py:260] loss = 1.9749228, step = 801 (4.995 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 20.1424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:01.325861 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 20.1424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.3115653, step = 901 (4.962 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:01.329045 140632884213504 basic_session_run_hooks.py:260] loss = 1.3115653, step = 901 (4.962 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 21.5963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:05.956321 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 21.5963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.0907857, step = 1001 (4.630 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:05.958779 140632884213504 basic_session_run_hooks.py:260] loss = 1.0907857, step = 1001 (4.630 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 20.6671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:10.794899 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 20.6671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.8017418, step = 1101 (4.839 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:10.797507 140632884213504 basic_session_run_hooks.py:260] loss = 1.8017418, step = 1101 (4.839 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 22.0349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:15.333127 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 22.0349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.0581894, step = 1201 (4.541 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:15.338393 140632884213504 basic_session_run_hooks.py:260] loss = 1.0581894, step = 1201 (4.541 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 20.6008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:20.187284 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 20.6008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.8521461, step = 1301 (4.851 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:20.189759 140632884213504 basic_session_run_hooks.py:260] loss = 1.8521461, step = 1301 (4.851 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 20.3326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:25.105502 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 20.3326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 1.098658, step = 1401 (4.919 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:25.108453 140632884213504 basic_session_run_hooks.py:260] loss = 1.098658, step = 1401 (4.919 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 20.6365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:29.951270 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 20.6365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.7258907, step = 1501 (4.845 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:29.953884 140632884213504 basic_session_run_hooks.py:260] loss = 0.7258907, step = 1501 (4.845 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 20.743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:34.772209 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 20.743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.9641935, step = 1601 (4.821 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:34.774594 140632884213504 basic_session_run_hooks.py:260] loss = 0.9641935, step = 1601 (4.821 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 21.5499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:39.412570 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 21.5499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.78956145, step = 1701 (4.640 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:39.415053 140632884213504 basic_session_run_hooks.py:260] loss = 0.78956145, step = 1701 (4.640 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 22.0406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:43.949654 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 22.0406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.8630886, step = 1801 (4.537 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:43.952388 140632884213504 basic_session_run_hooks.py:260] loss = 0.8630886, step = 1801 (4.537 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 20.3688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:48.859143 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 20.3688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.9648005, step = 1901 (4.909 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:48.861786 140632884213504 basic_session_run_hooks.py:260] loss = 0.9648005, step = 1901 (4.909 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 20.0191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:53.854405 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 20.0191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.62376827, step = 2001 (4.995 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:53.856942 140632884213504 basic_session_run_hooks.py:260] loss = 0.62376827, step = 2001 (4.995 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step/sec: 20.8675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:58.646502 140632884213504 basic_session_run_hooks.py:692] global_step/sec: 20.8675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.5157718, step = 2101 (4.795 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:11:58.652230 140632884213504 basic_session_run_hooks.py:260] loss = 0.5157718, step = 2101 (4.795 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoints for 2197 into results/model/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:03.358116 140632884213504 basic_session_run_hooks.py:606] Saving checkpoints for 2197 into results/model/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:03.575153 140632884213504 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:05.296194 140632884213504 estimator.py:1147] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation at 2019-09-16T13:12:05Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:05.326854 140632884213504 evaluation.py:255] Starting evaluation at 2019-09-16T13:12:05Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:05.436950 140632884213504 monitored_session.py:240] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring parameters from results/model/model.ckpt-2197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:05.446096 140632884213504 saver.py:1284] Restoring parameters from results/model/model.ckpt-2197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:05.565072 140632884213504 session_manager.py:500] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:05.603835 140632884213504 session_manager.py:502] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:06.194922 140632884213504 evaluation.py:167] Evaluation [10/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:06.346421 140632884213504 evaluation.py:167] Evaluation [20/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:06.480542 140632884213504 evaluation.py:167] Evaluation [30/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:06.646681 140632884213504 evaluation.py:167] Evaluation [40/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:06.831157 140632884213504 evaluation.py:167] Evaluation [50/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:06.980172 140632884213504 evaluation.py:167] Evaluation [60/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:07.146540 140632884213504 evaluation.py:167] Evaluation [70/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:07.307970 140632884213504 evaluation.py:167] Evaluation [80/100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished evaluation at 2019-09-16-13:12:07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:07.532778 140632884213504 evaluation.py:275] Finished evaluation at 2019-09-16-13:12:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dict for global step 2197: acc = 0.9844603, f1 = 0.9844603, global_step = 2197, loss = 0.60091376, precision = 0.9844603, recall = 0.9844603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:07.534750 140632884213504 estimator.py:2040] Saving dict for global step 2197: acc = 0.9844603, f1 = 0.9844603, global_step = 2197, loss = 0.60091376, precision = 0.9844603, recall = 0.9844603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 'checkpoint_path' summary for global step 2197: results/model/model.ckpt-2197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:07.711071 140632884213504 estimator.py:2100] Saving 'checkpoint_path' summary for global step 2197: results/model/model.ckpt-2197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for final step: 1.7712708.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:07.737202 140632884213504 estimator.py:368] Loss for final step: 1.7712708.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:07.793951 140632884213504 estimator.py:1145] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From <ipython-input-9-af9b34931eff>:103: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0916 13:12:08.319656 140632884213504 deprecation.py:323] From <ipython-input-9-af9b34931eff>:103: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:08.323126 140632884213504 estimator.py:1147] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:08.414020 140632884213504 monitored_session.py:240] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring parameters from results/model/model.ckpt-2197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:08.416880 140632884213504 saver.py:1284] Restoring parameters from results/model/model.ckpt-2197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:08.487478 140632884213504 session_manager.py:500] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0916 13:12:08.501235 140632884213504 session_manager.py:502] Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"GloVe Embeddings + bi-LSTM + CRF\"\"\"\n",
    "\n",
    "__author__ = \"Guillaume Genthial\"\n",
    "\n",
    "import functools\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tf_metrics import precision, recall, f1\n",
    "\n",
    "DATA_DIR = '../Data/4ner/'\n",
    "OBJECTS_DIR = '../objects/'\n",
    "\n",
    "# Logging\n",
    "Path('results').mkdir(exist_ok=True)\n",
    "tf.logging.set_verbosity(logging.INFO)\n",
    "handlers = [\n",
    "    logging.FileHandler('results/main.log'),\n",
    "    logging.StreamHandler(sys.stdout)\n",
    "]\n",
    "logging.getLogger('tensorflow').handlers = handlers\n",
    "\n",
    "\n",
    "def parse_fn(line_words, line_tags):\n",
    "    \"\"\" parse words and tags line by line\n",
    "        Note: tf need string encoded to `bytes`\n",
    "    \"\"\"\n",
    "    # Encode in Bytes for TF\n",
    "    words = [w.encode() for w in line_words.strip().split('\\t')[2:]]\n",
    "    tags = [t.encode() for t in line_tags.strip().split('\\t')[2:]]\n",
    "\n",
    "    assert len(words) == len(tags), f\"Words and tags lengths don't match\"\n",
    "    return (words, len(words)), tags\n",
    "\n",
    "\n",
    "def generator_fn(words, tags):\n",
    "    with Path(words).open('r') as f_words, Path(tags).open('r') as f_tags:\n",
    "        for line_words, line_tags in zip(f_words, f_tags):\n",
    "            yield parse_fn(line_words, line_tags)\n",
    "\n",
    "def input_fn(words, tags, params=None, shuffle_and_repeat=False):\n",
    "    params = params if params is not None else {}\n",
    "    shapes = (([None], ()), [None])\n",
    "    types = ((tf.string, tf.int32), tf.string)\n",
    "    defaults = (('<pad>', 0), 'O')\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        functools.partial(generator_fn, words, tags),\n",
    "        output_shapes=shapes, output_types=types)\n",
    "\n",
    "    if shuffle_and_repeat:\n",
    "        dataset = dataset.shuffle(params['buffer']).repeat(params['epochs']\n",
    "\n",
    "    # prefetch: ensure a batch of data is pre-loaded on the computing device\n",
    "    #           to avoid starvation (=wasting compute resources)\n",
    "    dataset = (dataset\n",
    "               .padded_batch(params.get('batch_size', 20), shapes, defaults)\n",
    "               .prefetch(1))\n",
    "\n",
    "#     iterator = dataset.make_one_shot_iterator()\n",
    "#     (words, nwords), tags = iterator.get_next()\n",
    "#     features = {'words': words, 'nwords': nwords}\n",
    "#     labels = {'tags': tags}\n",
    "#     return features, labels\n",
    "    return dataset\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    # For serving, features are a bit different\n",
    "    if isinstance(features, dict):\n",
    "        features = features['words'], features['nwords']\n",
    "\n",
    "    # Read vocabs and inputs\n",
    "    dropout = params['dropout']\n",
    "    words, nwords = features\n",
    "    training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    vocab_words = tf.contrib.lookup.index_table_from_file(\n",
    "        params['words'], num_oov_buckets=params['num_oov_buckets'])\n",
    "    with Path(params['tags']).open() as f:\n",
    "        indices = [idx for idx, tag in enumerate(f) if tag.strip(params['seprator']) != 'O']\n",
    "        num_tags = len(indices) + 1\n",
    "\n",
    "    # Word Embeddings\n",
    "    word_ids = vocab_words.lookup(words)\n",
    "    glove = np.load(params['glove'])['embeddings']  # np.array\n",
    "    variable = np.vstack([glove, [[0.]*params['dim']]])   # for unknown words\n",
    "    variable = tf.Variable(variable, dtype=tf.float32, trainable=False)\n",
    "    embeddings = tf.nn.embedding_lookup(variable, word_ids)\n",
    "    embeddings = tf.layers.dropout(embeddings, rate=dropout, training=training)\n",
    "\n",
    "    # LSTM\n",
    "    t = tf.transpose(embeddings, perm=[1, 0, 2])  # make time-major\n",
    "    lstm_cell_fw = tf.contrib.rnn.LSTMBlockFusedCell(params['lstm_size'])\n",
    "    lstm_cell_bw = tf.contrib.rnn.LSTMBlockFusedCell(params['lstm_size'])\n",
    "    lstm_cell_bw = tf.contrib.rnn.TimeReversedFusedRNN(lstm_cell_bw)\n",
    "    output_fw, _ = lstm_cell_fw(t, dtype=tf.float32, sequence_length=nwords)\n",
    "    output_bw, _ = lstm_cell_bw(t, dtype=tf.float32, sequence_length=nwords)\n",
    "    output = tf.concat([output_fw, output_bw], axis=-1)\n",
    "    output = tf.transpose(output, perm=[1, 0, 2])  # make batch-major\n",
    "    output = tf.layers.dropout(output, rate=dropout, training=training)\n",
    "\n",
    "    # CRF\n",
    "    logits = tf.layers.dense(output, num_tags)\n",
    "    crf_params = tf.get_variable(\"crf\", [num_tags, num_tags], dtype=tf.float32)\n",
    "    pred_ids, _ = tf.contrib.crf.crf_decode(logits, crf_params, nwords)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # Predictions\n",
    "        reverse_vocab_tags = tf.contrib.lookup.index_to_string_table_from_file(\n",
    "            params['tags'])\n",
    "        pred_strings = reverse_vocab_tags.lookup(tf.to_int64(pred_ids))\n",
    "        predictions = {\n",
    "            'pred_ids': pred_ids,\n",
    "            'tags': pred_strings\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "    else:\n",
    "        # Loss\n",
    "        vocab_tags = tf.contrib.lookup.index_table_from_file(params['tags'])\n",
    "        tags = vocab_tags.lookup(labels)\n",
    "        log_likelihood, _ = tf.contrib.crf.crf_log_likelihood(\n",
    "            logits, tags, nwords, crf_params)\n",
    "        loss = tf.reduce_mean(-log_likelihood)\n",
    "\n",
    "        # Metrics\n",
    "        weights = tf.sequence_mask(nwords)\n",
    "        metrics = {\n",
    "            'acc': tf.metrics.accuracy(tags, pred_ids, weights),\n",
    "            'precision': precision(tags, pred_ids, num_tags, indices, weights),\n",
    "            'recall': recall(tags, pred_ids, num_tags, indices, weights),\n",
    "            'f1': f1(tags, pred_ids, num_tags, indices, weights),\n",
    "        }\n",
    "        for metric_name, op in metrics.items():\n",
    "            tf.summary.scalar(metric_name, op[1])\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "        elif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            train_op = tf.train.AdamOptimizer().minimize(\n",
    "                loss, global_step=tf.train.get_or_create_global_step())\n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode, loss=loss, train_op=train_op)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Params\n",
    "    params = {\n",
    "        'dim': 300,\n",
    "        'dropout': 0.5,\n",
    "        'num_oov_buckets': 1,\n",
    "        'epochs': 25,\n",
    "        'batch_size': 20,\n",
    "        'buffer': 15000,\n",
    "        'lstm_size': 100,\n",
    "        'texts': str(Path(OBJECTS_DIR, 'train_corpus.pkl')),\n",
    "        #'tags': str(Path(OBJECTS_DIR, 'train_corpus_labels.pkl')),\n",
    "        'tags': str(Path(DATA_DIR, 'vocab.tags.txt')),\n",
    "        'words': str(Path(DATA_DIR, 'vocab.words.txt')),\n",
    "        'chars': str(Path(DATA_DIR, 'vocab.chars.txt')),\n",
    "        'glove': str(Path(DATA_DIR, 'glove.npz')),\n",
    "        'seprator': '\\t'\n",
    "    }\n",
    "\n",
    "    with Path('results/params.json').open('w') as f:\n",
    "        json.dump(params, f, indent=4, sort_keys=True)\n",
    "\n",
    "    def fwords(name):\n",
    "        return str(Path(DATA_DIR, '{}.words.txt'.format(name)))\n",
    "\n",
    "    def ftags(name):\n",
    "        return str(Path(DATA_DIR, '{}.tags.txt'.format(name)))\n",
    "\n",
    "    # Estimator, train and evaluate\n",
    "    train_inpf = functools.partial(input_fn, fwords('train'), ftags('train'),\n",
    "                                   params, shuffle_and_repeat=True)\n",
    "    eval_inpf = functools.partial(input_fn, fwords('train'), ftags('train'))\n",
    "\n",
    "    # serialize weights to disk every 2 mins\n",
    "    cfg = tf.estimator.RunConfig(save_checkpoints_secs=120)\n",
    "    estimator = tf.estimator.Estimator(model_fn, 'results/model', cfg, params)\n",
    "    Path(estimator.eval_dir()).mkdir(parents=True, exist_ok=True)\n",
    "    hook = tf.compat.v2.estimator.experimental.stop_if_no_increase_hook(\n",
    "        estimator, 'f1', 500, min_steps=8000, run_every_secs=120)\n",
    "    train_spec = tf.estimator.TrainSpec(input_fn=train_inpf, hooks=[hook])\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn=eval_inpf, throttle_secs=120)\n",
    "    print(\"finished loading\" * 10)\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "\n",
    "    # Write predictions to file\n",
    "    def write_predictions(name):\n",
    "        Path('results/score').mkdir(parents=True, exist_ok=True)\n",
    "        with Path('results/score/{}.preds.txt'.format(name)).open('wb') as f:\n",
    "            test_inpf = functools.partial(input_fn, fwords(name), ftags(name))\n",
    "            golds_gen = generator_fn(fwords(name), ftags(name))\n",
    "            preds_gen = estimator.predict(test_inpf)\n",
    "            for golds, preds in zip(golds_gen, preds_gen):\n",
    "                ((words, _), tags) = golds\n",
    "                for word, tag, tag_pred in zip(words, tags, preds['tags']):\n",
    "                    f.write(b' '.join([word, tag, tag_pred]) + b'\\n')\n",
    "                f.write(b'\\n')\n",
    "\n",
    "    for name in ['train']: #, 'testa', 'testb']:\n",
    "        write_predictions(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
